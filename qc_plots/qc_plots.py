from __future__ import print_function

import os
import sys
import numpy as np
import pandas as pd
import netCDF4
import argparse
import json
from contextlib import ExitStack
from pylab import *
from mpl_toolkits.axes_grid1 import make_axes_locatable
from PIL import Image
from datetime import datetime, timedelta
from pathlib import Path
from PyPDF2 import PdfFileWriter, PdfFileReader
from scipy.optimize import curve_fit
from scipy.stats import pearsonr
from subprocess import run
import tomli

import smtplib
from email.mime.multipart import MIMEMultipart
from email.mime.text import MIMEText
from email.mime.application import MIMEApplication
from email import encoders
from getpass import getpass

_default_leg_font_size = 7
_default_body = "This email was sent from the python program qc_plots"
_default_email_cfg = """
[server]
use_external_program = true

[server.program]
program = "mail"
subject_flag = "-s"
from_addr_flag = "-r"
attachment_flag = "-a"
body_arg = "stdin"

[server.smtp]
smtp_address = "localhost"
smtp_port = 0
# smtp_address = "smtp.gmail.com"
# smtp_address = "smtp.outlook.com"
# smtp_port = 587"

[email]
from = ""
to = "tccon-qaqc@gps.caltech.edu"
body = "Plots automatically generated by `tccon_qc_plots` on {date}"
subject_from_site_id = false
subject = "[#275]"

[email.sites]
ae = 226  # Ascension Island
an = 224  # Anmyeondo
bi = 213  # Bialystok
br = 236  # Bremen
bu = 220  # Burgos
ci = 210  # Caltech/Pasadena
db = 214  # Darwin
df = 225  # Armstrong/Dryden/Edwards
et = 227  # East Trout Lake
eu = 222  # Eureka
gm = 234  # Garmisch
hf = 276  # Hefei
hw = 274  # Harwell
iz = 216  # Izana
js = 233  # Saga
ka = 217  # Karlsruhe
ll = 219  # Lauder pre-2018 125HR
lr = 221  # Lauder post-2018 125HR
ni = 240  # Nicosia
ny = 237  # Ny-Alesund
oc = 223  # Lamont
or = 212  # Orleans
pa = 211  # Park Falls
pr = 231  # Paris
ra = 260  # Reunion
rj = 228  # Rikubetsu
so = 218  # Sodankyla
sp = 237  # Alternate abbreviation for Ny-Alesund?
tj = 229  # Tsukuba 120HR
tk = 229  # Tsukuba 125HR
wg = 215  # Wollongong
xh = 271  # Xianghe
zs = 235  # Zugspitze
"""


def send_email(subject,body,send_from,send_to,attachment,smtp_args=None,authenticate=False):
    """
    Sends an email with an attachement

    Inputs:
        - subject: email subject
        - body: email text
        - send_from: email address with which the email will be sent
        - send_to: email address the email will be sent to
        - attachment: full path to a file that will be attached to the email
        - smtp_args: if not passed, then the server and port are guessed from the `send_from`
          address (Gmail if "gmail" in the address, Outlook otherwise). If `smtp_args` is
          given, then it must be the sequence of arguments to pass to `smtplib.SMTP` to
          establish the connection - usually server and port.
        - authenticate: Ignored if `smtp_args` is `None`. Otherwise, setting this to `False`
          indicates that authentication is not necessary. Setting this to `True` means that
          a password is required, and will be prompted for interactively. If this is a string,
          then it is assumed to be a password.
    """

    # settup the message
    message = MIMEMultipart()
    message['From'] = send_from
    message['To'] = send_to
    message['Subject'] = subject
    message.attach(MIMEText(body,'plain'))
    with open(attachment,'rb') as infile:
        payload = MIMEApplication(infile.read(),_subtype='pdf')
    encoders.encode_base64(payload)
    payload.add_header('Content-Disposition','attachment',filename=os.path.basename(attachment))
    message.attach(payload)

    # send the message with SMTP
    if smtp_args is not None:
        if authenticate is True:
            passwd = getpass()
        if authenticate is not False:
            passwd = authenticate
            authenticate = True
    elif '@gmail' in send_from:
        smtp_args = ('smtp.gmail.com', 587)
        authenticate = True
        passwd = getpass()
    else:
        smtp_args = ('smtp.outlook.com', 587)
        authenticate = True
        passwd = getpass()
    with smtplib.SMTP(*smtp_args) as session:
        if authenticate:
            session.starttls() #enable security
            session.login(send_from, passwd) #login with mail_id and password
        session.sendmail(send_from, send_to, message.as_string())


def send_email_ext(subject, body, send_from, send_to, attachment, cfg):
    """Send an email using an external program.

    Inputs:
        - subject: email subject
        - body: email text
        - send_from: email address with which the email will be sent
        - send_to: email address the email will be sent to
        - attachment: full path to a file that will be attached to the email
        - cfg: a dictionary that specifies how to call the program. Usually
          this is the server/program section of the config .toml file.
    """
    aflag = cfg['attachment_flag']
    fflag = cfg['from_addr_flag']
    sflag = cfg['subject_flag']
    pgrm  = cfg['program']

    args = [pgrm, sflag, subject, fflag, send_from, aflag, attachment, send_to]
    if cfg['body_arg'] == 'stdin':
        run(args, input=body.encode('utf8'))
    else:
        raise NotImplementedError('body_arg == {} not implemented for sending an email by an external program'.format(cfg['body_arg']))


def send_email_from_config(cfg_file, site_id, attachment, nc_file):
    """Send an email using a config dictionary to determine how to send it.

    Inputs:
        - cfg_file: path to the .toml config file to read in
        - site_id: the two-letter site ID for the site whose data was plotted.
          Used to look up the corresponding GGGBugs subject line, if the config
          specifies to do so.
        - attachment: path to the .pdf file to attach.
    """
    with open(cfg_file) as f:
        cfg = tomli.load(f)

    # Get message parts that we'll need regardless of whether we're sending 
    # using smtplib or an external program

    to_addr = cfg['email']['to']
    from_addr = cfg['email']['from']
    body = cfg['email'].get('body', _default_body).format(date=pd.Timestamp.now().strftime('%Y-%m-%d %H:%M'), basename=os.path.basename(nc_file))
    if cfg['email']['subject_from_site_id']:
        try:
            subject = '[#{}]'.format(cfg['email']['sites'][site_id])
        except KeyError:
            raise KeyError('Unable to find a subject line for site ID {} in the config file {}'.format(site_id, cfg_file))
    else:
        subject = cfg['email']['subject']


    if cfg['server']['use_external_program']:
        send_email_ext(subject=subject, body=body, send_from=from_addr, send_to=to_addr, attachment=attachment, cfg=cfg['server']['program'])
    else:
        smtp_info = cfg['server']['smtp']
        smtp_args = [smtp_info['smtp_address'], smtp_info['port']]
        if 'password' in smtp_info:
            smtp_args.append(smtp_info['password'])
        req_auth = smtp_info.get('requires_auth', True)
        send_email(subject=subject, body=body, send_from=from_addr, send_to=to_addr, attachment=attachment, 
                   smtp_args=smtp_args, authenticate=req_auth)


class TcconData:
    def __init__(self, nc_dset, exclude_times=None, force_flag0=False):
        self.dset = nc_dset
        if nc_dset is None:
            self.time = None
            self.all_ids = None
            self.flag0_ids = None
            self.flagged_ids = None
        else:
            self.time = np.array([datetime(*cftime.timetuple()[:6]) for cftime in netCDF4.num2date(nc_dset['time'][:],units=nc_dset['time'].units,calendar=nc_dset['time'].calendar)])
            
            ids = np.ones(nc_dset['time'].size, dtype=np.bool_)
            flag0_ids = nc_dset['flag'][:] == 0
            flagged_ids = nc_dset['flag'][:] != 0
            if force_flag0 and 'flag' in nc_dset.variables:
                ids &= flag0_ids
            if exclude_times is not None:
                is_outside = (self.time < np.min(exclude_times)) | (self.time > np.max(exclude_times))
                ids &= is_outside
                flag0_ids &= is_outside
                flagged_ids &= is_outside

            self.all_ids = np.flatnonzero(ids)
            self.flag0_ids = np.flatnonzero(flag0_ids)
            self.flagged_ids = np.flatnonzero(flagged_ids)

    @classmethod
    def create(cls, filepath, stack, force_flag0, exclude_times=None):
        if filepath:
            dset = stack.enter_context(netCDF4.Dataset(filepath,'r')) # input reference netcdf file
            return cls(dset, exclude_times=exclude_times, force_flag0=force_flag0)
        else:
            return cls(None)


def cm2inch(*tupl):
    """
    Converts reasonable units (cm) into terrible units (inches).
    """
    inch = 2.54
    if isinstance(tupl[0], tuple):
        return tuple(i/inch for i in tupl[0])
    else:
        return tuple(i/inch for i in tupl)


def get_limits(nc,var,json_limits=None):
    """
    Get the axis ranges for variables.

    This hardcodes specific limits for some variables.

    A given variable can be listed in the limits.json file to overwrite the axis range of specific variables.

    If the variable has no hardcoded limits here or is not listed in the limits.json file, the vmin and vmax values for that variable are used (from the qc.dat file and saved as variable metadata in the netcdf file)
    """

    limits = [None,None]

    # special cases for difference plots
    if type(var)==list and np.any([v in var for v in ['tout','pout','h2o_dmf_out']]):
        json_dif_limits = {key.strip('_dif'):val for key,val in json_limits.items() if key.endswith('_dif')}
        if json_dif_limits and np.any([key in var for key in json_dif_limits]):
            for key in json_dif_limits:
                if key in var:
                    limits = json_dif_limits[key]
        elif 'tout' in var:
            limits = [-15,15] # degrees K and C (it's a difference)
        elif 'pout' in var:
            limits = [-10,10] # hPa
        elif 'h2o_dmf_out' in var:
            limits = [-0.01,0.01] # parts
        return limits
    elif type(var)==list: # for the rest just get the range of the concerned variable, this will likely be too large for differences
        return get_limits(nc,var[0],json_limits=json_limits)

    # "regular" series
    if json_limits and var in json_limits:
        limits = json_limits[var]
    elif 'vsf_h2o' in var or 'vsf_hdo' in var or 'vsf_hf' in var:
        limits = [0.3,2]
    elif 'vsf_hcl' in var:
        limits = [0.7,1.4]
    elif 'vsf_' in var:
        limits = [0.9,1.1]
    elif var.endswith('_fs'):
        limits = [-2,2]
    elif var.endswith('_sg'):
        limits = [-8,8]
    elif var.endswith('_zo'):
        limits = [-0.006,0.006]
    elif var.endswith('_cfampocl'):
        limits = [0,0.005]
    elif var.endswith('_cfperiod'):
        limits = [-1,50]
    elif var == 'xluft':
        limits = [0.975,1.025]
    elif var == 'xch4':
        limits = [1.6,2.0]
    elif var == 'xco':
        limits = [0,200]
    elif var == 'xn2o':
        limits = [200,400]
    elif var == 'xhdo':
        limits = [0,10000]
    elif var == 'xh2o':
        limits = [0,10000]
    elif var == 'xch4_error':
        limits = [0,0.05]
    elif var == 'xco_error':
        limits = [0,10]
    elif var == 'xhdo_error':
        limits = [0,100]
    elif var == 'xh2o_error':
        limits = [0,100]
    elif var == 'xhf_error':
        limits = [0,50]
    elif var == 'xn2o_error':
        limits = [0,25]
    elif var == 'dip':
        limits = [-0.05,0.05]
    elif var == 'mvd':
        limits = [-5,250]
    elif var == 'lse':
        limits = [-0.1,0.1]
    elif var == 'lsu':
        limits = [0,0.06]
    elif var == 'fvsi':
        limits = [0.0,20]
    elif 'vmin' in nc.dset[var].__dict__:
        limits = [nc.dset[var].vmin,nc.dset[var].vmax]  

    return limits


def get_time_xlims(nc_time, context_time):
    x1 = np.min(nc_time) - timedelta(days=2)
    x2 = np.max(nc_time) + timedelta(days=2)
    if context_time is not None:
        x1 = min(x1, np.min(context_time) - timedelta(days=2))
        x2 = max(x2, np.max(context_time) + timedelta(days=2))

    return x1, x2


def make_fig(args,nc,xvar,yvar,width=20,height=10,kind='',freq='',varlimits=None):
    two_subplots = type(yvar)==list and type(yvar[0])==list
    if two_subplots:
        fig,axes = subplots(2,1,sharex=True,gridspec_kw={'height_ratios':[1,3]})
        axes[0].grid()
        axes[1].grid()
        yvar2 = yvar[0][1] # for the top plot
        yvar = yvar[0][0] # for the bottom plot
        ax = axes[1] # the bottom plot
        if 'units' in nc.dset[yvar2].__dict__:
            axes[0].set_ylabel('{} ({})'.format(yvar2,nc.dset[yvar2].units))
        else:
            axes[0].set_ylabel(yvar2)
    else:
        fig,ax = subplots()
        ax.grid()
    fig.set_size_inches(cm2inch(width,height))
    
    if kind:
        fig.suptitle('{} of data resampled with frequency={}'.format(kind,freq))

    if not args.show_all:
        if kind!='std':
            ax.set_ylim(get_limits(nc,yvar,json_limits=varlimits))
        if xvar!='time':
            ax.set_xlim(get_limits(nc,xvar,json_limits=varlimits))
        if two_subplots:
            axes[0].set_ylim(get_limits(nc,yvar2,json_limits=varlimits))

    if type(yvar)==list:
        ylab = '{} minus {}'.format(*yvar)
        yvar = yvar[0]
    else:
        ylab = yvar

    if 'units' in nc.dset[yvar].__dict__:
        ax.set_ylabel('{} ({})'.format(ylab,nc.dset[yvar].units))
    else:
        ax.set_ylabel(ylab)

    if xvar!='time' and 'units' in nc.dset[xvar].__dict__:
        ax.set_xlabel('{} ({})'.format(xvar,nc.dset[xvar].units))
    else:
        ax.set_xlabel(xvar)

    if two_subplots:
        ax = axes
    return fig,ax


def add_qc_lines(args,nc,ax,xvar,yvar,kind=''):
    for elem in ['vmin','vmax']:
        if type(yvar)!=list and kind!='std' and (elem in nc.dset[yvar].__dict__): # don't add the line for difference plots and standard deviation plots
            ax.axhline(y=nc.dset[yvar].__dict__[elem],linestyle='dashed',color='black')
        if elem in nc.dset[xvar].__dict__:
            ax.axvline(x=nc.dset[xvar].__dict__[elem],linestyle='dashed',color='black')


def savefig(fig,code_dir,xvar,yvar,plot_type='sc',tight=True):
    if type(yvar)==list and type(yvar[0])==list:
        fig_name = '{}_and_{}_VS_{}_{}.png'.format(yvar[0][0],yvar[0][1],xvar,plot_type)
    elif type(yvar)==list:
        fig_name = '{}_minus_{}_VS_{}_{}.png'.format(yvar[0],yvar[1],xvar,plot_type)
    else:
        fig_name = '{}_VS_{}_{}.png'.format(yvar,xvar,plot_type)
    fig_path = os.path.join(code_dir.parent,'outputs',fig_name)
    if tight:
        tight_layout()
    fig.savefig(fig_path,dpi=300)
    return fig_path


def lin_model(x,a,b):
    return a*x+b


def add_linfit(ax,x,y,yerr=None,leg='Fit to flag==0 data: {}',color='C1'):
    """
    Add a line with the results of a linear fit to y = a*x + b
    Also shows the squared pearson correlation coefficient

    Inputs:
        - ax: matplotlib subplot
        - x: x axis data
        - y: y axis data
    """
    x = np.array(x)
    y = np.array(y)
    
    # linear fit using y = a*x + b
    if yerr:
        yerr = np.array(yerr)
        fit,cov = curve_fit(lin_model,x,y,p0=[1,0],sigma=yerr)
    else:
        fit,cov = curve_fit(lin_model,x,y,p0=[1,0])
    
    # pearson correlation coefficient
    R = pearsonr(x,y)[0]

    fitstr = 'y=({:.4f} $\pm$ {:.4f})*x + ({:.4f} $\pm$ {:.4f}); R²={:.3f}'.format(fit[0],np.sqrt(cov[0][0]),fit[1],np.sqrt(cov[1][1]),R**2)
    leg = leg.format(fitstr)

    # plot line fits
    ax.plot(x,lin_model(x,fit[0],fit[1]),linestyle='--',dashes=(5,20),label=leg,color=color)


def split_by_gaps(df,gap,time):
    """
    Split an input dataframe with a datetime variable into a groupby dataframe with each group having data without gaps larger than the "gap" variable

    Inputs:
        - df: pandas dataframe with a datetime
        - time: column name of the datetime variable
        - gaps: minimum gap length, a string compatible with pandas Timedelta https://pandas.pydata.org/pandas-docs/stable/user_guide/timedeltas.html
    Outputs:
        - df_by_gaps: groupby object with each group having data without gaps larger than the "gap" variable
    """

    df[1] = df[time].diff() > pd.Timedelta(gap)
    df[1] = df[1].apply(lambda x: 1 if x else 0).cumsum()
    df_by_gaps = df.groupby(1)

    return df_by_gaps


def make_rolling_plots(args,nc,context,xvar,yvar,kind='',freq='',varlimits=None):
    """
    Make a plot of yvar vs xvar with rolling stats and return the figure object
    """
    stat_list = xvar.split('_')[1:]
    xvar = 'time'

    ydata = nc.dset[yvar][:]

    fig,ax = make_fig(args,nc,xvar,yvar,kind=kind,freq=freq,varlimits=varlimits)
    ax.set_xlim(get_time_xlims(nc.time, context.time))

    #if not args.flag0:
    #    ax.plot(nc_time[flagged],ydata[flagged],linewidth=0,marker='o',markersize=1,color='red',label='{} flagged'.format(nc.long_name))
    ax.plot(nc.time[nc.flag0_ids],ydata[nc.flag0_ids],linewidth=0,marker='o',markersize=1,color='royalblue',label='{} flag=0'.format(nc.dset.long_name))

    df = pd.DataFrame().from_dict({'x':nc.time[nc.flag0_ids],'y':ydata[nc.flag0_ids]})
    df_by_gaps = split_by_gaps(df,args.roll_gaps,'x')

    color = {'mean':'hotpink','median':'black','std':'green'}
    first = True
    for N,group in df_by_gaps:
        for stat in stat_list:           
            stat_group = getattr(group.rolling(args.roll_window,center=True,min_periods=1),stat)()

            if first:
                ax.plot(group['x'],stat_group['y'],color=color[stat],label='{} spectra rolling {}'.format(args.roll_window,stat),linewidth=0,marker='o',markersize=1)
            else:
                ax.plot(group['x'],stat_group['y'],color=color[stat],linewidth=0,marker='o',markersize=1)
            
            if stat == 'mean':
                stat_group['ystd'] = group.rolling(args.roll_window,center=True).std()['y']
                if first:
                    ax.plot(group['x'],stat_group['y']+stat_group['ystd'],color='green',label='Rolling std',linewidth=0,marker='o',markersize=1)
                else:
                    ax.plot(group['x'],stat_group['y']+stat_group['ystd'],color='green',linewidth=0,marker='o',markersize=1)
                ax.plot(group['x'],stat_group['y']-stat_group['ystd'],color='green',linewidth=0,marker='o',markersize=1)
        first = False
    ax.legend(fontsize=_default_leg_font_size)
    add_qc_lines(args,nc,ax,xvar,yvar,kind='')

    return fig

def make_scatter_plots(args,nc,ref,context,xvar,yvar,kind='',freq='',varlimits=None):
    """
    Make a plot of xvar vs yvar and return the figure object
    """

    if xvar.startswith('roll'):
        fig = make_rolling_plots(args,nc,context,xvar,yvar,varlimits=varlimits)
        return fig

    if xvar not in nc.dset.variables:
        xvar = 'time'

    fig,ax = make_fig(args,nc,xvar,yvar,kind=kind,freq=freq,varlimits=varlimits)  

    two_subplots = type(yvar)==list and type(yvar[0])==list

    if xvar != 'time':
        # add invisible axis to make the plot the same size as the hexbin plots with colorbars
        divider = make_axes_locatable(ax)
        cax = divider.append_axes("right", size="3%", pad=0.1)
        cax.axis('off')
        if args.context:
            cax = divider.append_axes("right", size="3%", pad=1.0)
            cax.axis('off')

            

    if two_subplots:
        ax2 = ax[0]
        ax = ax[1]
        yvar2 = yvar[0][1]
        yvar = yvar[0][0]
        ydata = nc.dset[yvar][:]
        ydata2 = nc.dset[yvar2][:]
        if args.ref and args.flag0 and 'flag' in ref.dset.variables:
            ref_data = ref.dset[yvar][ref.flag0_ids]
            ref_data2 = ref.dset[yvar2][ref.flag0_ids]            
        elif args.ref:
            ref_data = ref.dset[yvar][:]
            ref_data2 = ref.dset[yvar2][:]

        divider = make_axes_locatable(ax2)
        cax2 = divider.append_axes("right", size="3%", pad=0.1)
        cax2.axis('off')

        if args.context:
            # add invisible axis to make the plot the same size as the hexbin plots with colorbars

            # context_flag0 is always set by get_support_file_data, it's just
            # all indices (outside the time of the main data) if !args.flag0
            context_data = context.dset[yvar][context.flag0_ids]
            context_data2 = context.dset[yvar2][context.flag0_ids]
            cax2 = divider.append_axes("right", size="3%", pad=1.0)
            cax2.axis('off')

    elif type(yvar)==list:
        ydata = nc.dset[yvar[0]][:]-nc.dset[yvar[1]][:] # used for the resampled plots without --flag0
        if args.ref and args.flag0 and 'flag' in ref.dset.variables:
            ref_data = ref.dset[yvar[0]][ref.flag0_ids]-ref.dset[yvar[1]][ref.flag0_ids]
        elif args.ref:
            ref_data = ref.dset[yvar[0]][:]-ref.dset[yvar[1]][:]

        if args.context:
            context_data = context.dset[yvar[0]][context.flag0_ids] - context.dset[yvar[1]][context.flag0_ids]
    else:
        ydata = nc.dset[yvar][:] # used for the resampled plots without --flag0
        if args.ref and args.flag0 and 'flag' in ref.dset.variables:
            ref_data = ref.dset[yvar][ref.flag0_ids]
        elif args.ref:
            ref_data = ref.dset[yvar][:]

        if args.context:
            context_data = context.dset[yvar][context.flag0_ids]

    if len(set(list(ydata))) in [1,0]:
        ax.text(0.5,0.5,'{} is constant'.format(yvar),transform=ax.transAxes,color='black')

    if kind:
        if args.flag0:
            ydata = ydata[nc.flag0_ids]
            if two_subplots:
                ydata2 = ydata2[nc.flag0_ids]
        data_dict = {'x':nc.time,'y':ydata}
        if two_subplots:
            data_dict['y2'] = ydata2
            
        main_frame = getattr(pd.DataFrame().from_dict(data_dict).set_index('x').resample(freq),kind)()

        ydata = main_frame['y'].values
        nc_reduced_times = np.array([pd.Timestamp(x).to_pydatetime() for x in main_frame.index])
        if two_subplots:
            ydata2 = main_frame['y2'].values

        if args.ref:
            ref_data_dict = {'x':ref.time,'y':ref_data}
            if two_subplots:
                ref_data_dict['y2'] = ref_data2                
            
            ref_frame = getattr(pd.DataFrame().from_dict(ref_data_dict).set_index('x').resample(freq),kind)()  

            ref_data = ref_frame['y'].values
            ref_time = np.array([pd.Timestamp(x).to_pydatetime() for x in ref_frame.index])
            if two_subplots:
                ref_data2 = ref_frame['y2'].values

        if args.context:
            context_data_dict = {'x':context.time,'y':context_data}
            if two_subplots:
                context_data_dict['y2'] = context_data2
            context_frame = getattr(pd.DataFrame().from_dict(context_data_dict).set_index('x').resample(freq),kind)()

            context_data = context_frame['y'].values
            if two_subplots:
                context_data2 = context_frame['y2'].values

    if xvar == 'time':
        ax.set_xlim(get_time_xlims(nc.time, context.time))
        if args.ref:
            ax.plot(ref.time,ref_data,linewidth=0,marker='o',markersize=1,color='lightgray',label=ref.dset.long_name)
            if two_subplots:
                ax2.plot(ref.time,ref_data2,linewidth=0,marker='o',markersize=1,color='lightgray')
        if args.context:
            ax.plot(context.time,context_data,linewidth=0,marker='o',markersize=1,color='deepskyblue',label='{} full record'.format(context.dset.long_name))
            if two_subplots:
                ax2.plot(context.time, context_data2, linewidth=0, marker='o', markersize=1, color='deepskyblue')
        if kind:
            ax.plot(nc_reduced_times,ydata,linewidth=0,marker='o',markersize=1,color='royalblue',label=nc.dset.long_name)
            if two_subplots:
               ax2.plot(nc_reduced_times,ydata2,linewidth=0,marker='o',markersize=1,color='royalblue') 
        else:
            if not args.flag0:
                ax.plot(nc.time[nc.flagged_ids],ydata[nc.flagged_ids],linewidth=0,marker='o',markersize=1,color='red',label='{} flagged'.format(nc.dset.long_name))
                if two_subplots:
                    ax2.plot(nc.time[nc.flagged_ids],ydata2[nc.flagged_ids],linewidth=0,marker='o',markersize=1,color='red')
            ax.plot(nc.time[nc.flag0_ids],ydata[nc.flag0_ids],linewidth=0,marker='o',markersize=1,color='royalblue',label='{} flag=0'.format(nc.dset.long_name))
            if two_subplots:
                ax2.plot(nc.time[nc.flag0_ids],ydata2[nc.flag0_ids],linewidth=0,marker='o',markersize=1,color='royalblue')
    else:
        if not args.flag0:
            ax.plot(nc.dset[xvar][nc.flagged_ids],ydata[nc.flagged_ids],linewidth=0,marker='o',markersize=1,color='red',label='{} flagged'.format(nc.dset.long_name))
            if two_subplots:
                ax2.plot(nc.dset[xvar][nc.flagged_ids],ydata2[nc.flagged_ids],linewidth=0,marker='o',markersize=1,color='red')
        x = nc.dset[xvar][nc.flag0_ids]
        y = ydata[nc.flag0_ids]
        ax.plot(x,y,linewidth=0,marker='o',markersize=1,color='royalblue',label='{} flag=0'.format(nc.dset.long_name))
        add_linfit(ax,x,y) # only add the linear fit to the flag=0 data, even when plotting all data      

        if args.context:
            context_x = context.dset[xvar][context.flag0_ids]
            ax.plot(context_x, context_data, linewidth=0, marker='o', markersize=1, color='deepskyblue', zorder=0.5, label='{} full record'.format(context.dset.long_name))

        if two_subplots:
            ax2.plot(x,ydata2[nc.flag0_ids],linewidth=0,marker='o',markersize=1,color='royalblue')
            if args.context:
                ax2.plot(context_x, context_data2, linewidth=0, marker='o', markersize=1, color='deepskyblue', zorder=0.5)

    # if the variables have a vmin and/or vmax attribute, add lines to the plot
    add_qc_lines(args,nc,ax,xvar,yvar,kind='')
    if two_subplots:
        add_qc_lines(args,nc,ax2,xvar,yvar2,kind='')

    ax.legend(fontsize=_default_leg_font_size)

    return fig    


def make_hexbin_plots(args,nc,context,xvar,yvar,varlimits=None):
    fig,ax = make_fig(args,nc,xvar,yvar,varlimits=varlimits)
    if type(yvar)==list:
        if not args.flag0:
            ydata = nc.dset[yvar[0]][:]-nc.dset[yvar[1]][:]
        else:
            ydata = nc.dset[yvar[0]][nc.flag0_ids]-nc.dset[yvar[1]][nc.flag0_ids]

        if args.context:
            # context_flag0 is set by get_support_file_data to be either
            # the flag == 0 data and the data outside the times of the 
            # main data, or just the latter. It already accounts for args.flag0
            context_ydata = context[yvar[0]][context.flag0_ids] - context[yvar[1]][context.flag0_ids]
    else:
        if not args.flag0:
            ydata = nc.dset[yvar][:]
        else:
            ydata = nc.dset[yvar][nc.flag0_ids]

        if args.context:
            context_ydata = context[yvar][context.flag0_ids]

    if args.flag0:
        xdata = nc.dset[xvar][nc.flag0_ids]
    else:
        xdata = nc.dset[xvar][:]

    if args.context:
        context_xdata = context[xvar][context.flag0_ids]

    if type(yvar)==list:
        yvar = yvar[0]

    xmin, xmax = get_limits(nc,xvar,json_limits=varlimits)
    ymin, ymax = get_limits(nc,yvar,json_limits=varlimits)
    if None in [xmin,xmax]:
        xmin, xmax = [np.nanmin(xdata), np.nanmax(xdata)]
    if None in [ymin,ymax]:
         ymin, ymax = [np.nanmin(ydata), np.nanmax(ydata)]

    extent = (xmin, xmax, ymin, ymax)

    hb = ax.hexbin(xdata,ydata,bins='log',mincnt=1,extent=extent,cmap=args.cmap,linewidths=(0,))
    divider = make_axes_locatable(ax)
    cax = divider.append_axes("right", size="3%", pad=0.1)
    cb = fig.colorbar(hb,cax=cax,label='{} current data'.format(nc.dset.long_name) if args.context else '')

    add_linfit(ax,nc.dset[xvar][nc.flag0_ids],nc.dset[yvar][nc.flag0_ids])

    if args.context:
        # use zorder to push this behind the main data
        hb2 = ax.hexbin(context_xdata, context_ydata, bins='log', mincnt=1, extent=extent, cmap='Greys', linewidths=(0,), zorder=0.5)
        cax2 = divider.append_axes('right', size='3%', pad=1.0)
        cb2 = fig.colorbar(hb2, cax=cax2, label='{} full record'.format(context.long_name))
        context_legend = 'Fit to flag==0 context data: {}' if args.flag0 else 'Fit to all context data: {}'
        add_linfit(ax,context[xvar][context.flag0_ids], context[yvar][context.flag0_ids], color='k', leg=context_legend)

    add_qc_lines(args,nc,ax,xvar,yvar)
    ax.legend(fontsize=_default_leg_font_size-2)
    #tight_layout()

    return fig


def flag_analysis(code_dir,nc):
    """
    Make a histogram to summarize flags
    """
    flag_df = pd.DataFrame()
    flag_df_pcnt = pd.DataFrame()
    flag_set = list(set(nc.dset['flag'][:]))
    N = nc.dset['time'].size
    print('Summary of flags:')
    print('  #  Parameter              N_flag      %')
    nflag_tot = 0
    for flag in sorted(flag_set):
        if flag==0:
            continue
        where_flagged = nc.dset['flag'][:]==flag
        nflag = np.count_nonzero(where_flagged)
        nflag_pcnt = 100*nflag/N
        nflag_tot += nflag
        flagged_var_name = list(nc.dset['flagged_var_name'][where_flagged])[0]
        print('{:>3}  {:<20} {:>6}   {:>8.3f}'.format(flag,flagged_var_name,nflag,nflag_pcnt))
        flag_df[flagged_var_name] = pd.Series([nflag])
        flag_df_pcnt[flagged_var_name] = pd.Series([nflag_pcnt])
    
    print('     {:<20} {:>6}   {:>8.3f}'.format('TOTAL',nflag_tot,100*nflag_tot/N))
    flag_df['Total'] = nflag_tot
    flag_df_pcnt['Total'] = 100*nflag_tot/N

    drop_list = [var for var in flag_df_pcnt if flag_df_pcnt[var][0]<1]
    flag_df = flag_df.drop(columns=drop_list)
    flag_df_pcnt = flag_df_pcnt.drop(columns=drop_list)
    
    fig, ax = subplots(2,1)
    fig.set_size_inches(cm2inch(20,10))
    ax[0].set_ylabel('Count')
    ax[1].set_ylabel('Count (%)')
    ax[0].set_title('{} total spectra from {}'.format(N,nc.dset.long_name))
    fig.suptitle('Summary of flags with count>1%')
    barplot = flag_df.plot(kind='bar',ax=ax[0])
    barplot_pcnt = flag_df_pcnt.plot(kind='bar',ax=ax[1],legend=False)
    for elem in ax:
        elem.axes.get_xaxis().set_visible(False)
        elem.grid()
    ax[0].legend(fontsize=_default_leg_font_size)#prop=dict(size=8))

    prec = ['{:.0f}','{:.2f}']
    for i,curplot in enumerate([barplot,barplot_pcnt]):
        for p in curplot.patches:
            curplot.annotate(prec[i].format(p.get_height()), (p.get_x() * 1.005, p.get_height() * 1.005))

    fig_path = os.path.join(code_dir.parent,'outputs','flags_summary.png')
    tight_layout()
    fig.savefig(fig_path,dpi=300)

    return fig_path


def simple_plots(args,code_dir,nc,ref,context,vardata,xvar,kind='',freq='',varlimits=None):
    """
    Make all the plots associated with a given horizontal axis variable, save them, and returns a list of the file paths to the figures.
    """
    fig_path_list = []
    if xvar != 'time' and not kind and not xvar.startswith('roll'): # tight layout messes with the correlation plots
        tight = False
    else:
        tight = True
    for yvar in vardata[xvar]:
        if type(yvar)==list and type(yvar[0])==list: # two plots with 1:3 ratio
            check = False
            for v in yvar[0]:
                if v not in nc.dset.variables:
                    print('\t',v,'is not in the netCDF file')
                    check = True
                elif check_mask(nc.dset[v]):
                    print('\t',v,'has only masked values')
                    check = True
            if check:
                continue
            print("\t {} and {}".format(*yvar[0]))
            fig_path_list += [savefig(make_scatter_plots(args,nc,ref,context,xvar,yvar,kind=kind,freq=freq,varlimits=varlimits),code_dir,xvar,yvar,plot_type='sc',tight=tight)]
        elif type(yvar)==list: # difference plot
            check = False
            for v in yvar:
                if v not in nc.dset.variables:
                    print('\t',v,'is not in the netCDF file')
                    check = True
                elif check_mask(nc.dset[v]):
                    print('\t',v,'has only masked values')
                    check = True
            if check:
                continue
            print("\t {} minus {}".format(*yvar))
            fig_path_list += [savefig(make_scatter_plots(args,nc,ref,context,xvar,yvar,kind=kind,freq=freq,varlimits=varlimits),code_dir,xvar,yvar,plot_type='sc',tight=tight)]
        else:
            if yvar not in nc.dset.variables:
                print('\t',yvar,'is not in the netCDF file')
                continue
            elif check_mask(nc.dset[yvar]):
                print('\t',yvar,'has only masked values')
                continue
            if kind:
                print(yvar,freq,kind)
            elif xvar.startswith('roll'):
                print(yvar,xvar)
            else:
                print('\t',yvar)
            fig_path_list += [savefig(make_scatter_plots(args,nc,ref,context,xvar,yvar,kind=kind,freq=freq,varlimits=varlimits),code_dir,xvar,yvar,plot_type='sc',tight=tight)]
            close('all')

            if xvar!='time' and not np.count_nonzero([i in xvar for i in ['median','mean','std']]):
                fig_path_list += [savefig(make_hexbin_plots(args,nc,context,xvar,yvar,varlimits=varlimits),code_dir,xvar,yvar,plot_type='hex',tight=tight)]
                close('all')
    return fig_path_list


def default_plots(args,code_dir,nc,varlimits=None):
    """
    Make (70-80 SZA AM - 70-80 SZA PM) and (70-80 SZA PM - 40-50 SZA PM) plots for xluft
    """

    fig_path_list = []
    if 'xluft' not in nc.dset.variables:
        return fig_path_list

    xluft = nc.dset['xluft'][:]
    solzen = nc.dset['solzen'][:]
    azim = nc.dset['azim'][:]

    df = pd.DataFrame().from_dict({'x':nc.time,'y':xluft})

    all_ids = np.arange(nc.dset['xluft'].size)

    AM = all_ids[azim<=180]
    PM = all_ids[azim>180]

    high_sza = all_ids[(70<=solzen) & (solzen<=80)]
    mid_sza = all_ids[(40<=solzen) & (solzen<=50)]
    low_sza = all_ids[(20<=solzen) & (solzen<=30)]

    if args.flag0:
        all_ids = nc.flag0_ids

    AM_high_sza = np.array(set(all_ids).intersection(set(AM),set(high_sza)))
    PM_high_sza = np.array(set(all_ids).intersection(set(PM),set(high_sza)))

    AM_mid_sza = np.array(set(all_ids).intersection(set(AM),set(mid_sza)))
    PM_mid_sza = np.array(set(all_ids).intersection(set(PM),set(mid_sza)))

    AM_low_sza = np.array(set(all_ids).intersection(set(AM),set(low_sza)))
    PM_low_sza = np.array(set(all_ids).intersection(set(PM),set(low_sza)))

    df_AM_high_sza = df.loc[AM_high_sza].set_index('x').resample('W').median()
    df_PM_high_sza = df.loc[PM_high_sza].set_index('x').resample('W').median()
    df_AM_mid_sza = df.loc[AM_mid_sza].set_index('x').resample('W').median()
    df_PM_mid_sza = df.loc[PM_mid_sza].set_index('x').resample('W').median()
    df_AM_low_sza = df.loc[AM_low_sza].set_index('x').resample('W').median()
    df_PM_low_sza = df.loc[PM_low_sza].set_index('x').resample('W').median()

    # 70-80 SZA AM and 70-80 SZA PM
    if df_AM_high_sza['y'].size!=0 and df_PM_high_sza['y'].size!=0:
        fig,ax = make_fig(args,nc,'time','xluft',width=20,height=10,kind='',freq='',varlimits=varlimits)
        ax.set_title('Weekly medians')
        if not varlimits or (varlimits and 'xluft' not in varlimits):
            ax.set_ylim(0.975,1.025)
        df_AM_high_sza['y'].plot(ax=ax,marker='o',markersize=1,linewidth=0,color='royalblue',label='70<=SZA<=80 AM')
        df_PM_high_sza['y'].plot(ax=ax,marker='o',markersize=1,linewidth=0,color='red',label='70<=SZA<=80 PM')
        fig_path = os.path.join(code_dir.parent,'outputs','xluft_high_sza_AM_high_sza_PM_vs_time.png')
        ax.grid()
        ax.legend(fontsize=_default_leg_font_size)
        if not args.flag0:
            add_qc_lines(args,nc,ax,'time','xluft')
        tight_layout()
        fig.savefig(fig_path,dpi=300)
        close('all')
        fig_path_list += [fig_path]

    # 70-80 SZA PM and 40-50 SZA PM and 20-30 SZA PM
    if df_PM_high_sza['y'].size!=0 and df_PM_mid_sza['y'].size!=0:
        fig,ax = make_fig(args,nc,'time','xluft',width=20,height=10,kind='',freq='',varlimits=varlimits)
        ax.set_title('Weekly medians')
        if not varlimits or (varlimits and 'xluft' not in varlimits):
            ax.set_ylim(0.975,1.025)
        df_PM_high_sza['y'].plot(ax=ax,marker='o',markersize=1,linewidth=0,color='royalblue',label='70<=SZA<=80 PM')
        df_PM_mid_sza['y'].plot(ax=ax,marker='o',markersize=1,linewidth=0,color='red',label='40<=SZA<=50 PM')
        if df_PM_low_sza['y'].size!=0:
            df_PM_low_sza['y'].plot(ax=ax,marker='o',markersize=1,linewidth=0,color='green',label='20<=SZA<=30 PM')
        ax.grid()
        ax.legend(fontsize=_default_leg_font_size)
        if not args.flag0:
            add_qc_lines(args,nc,ax,'time','xluft')
        fig_path = os.path.join(code_dir.parent,'outputs','xluft_sza_PM_vs_time.png')
        tight_layout()
        fig.savefig(fig_path,dpi=300)
        close('all')
        fig_path_list += [fig_path]

    # 70-80 SZA PM and 40-50 SZA PM and 20-30 SZA PM
    if df_AM_high_sza['y'].size!=0 and df_AM_mid_sza['y'].size!=0:
        fig,ax = make_fig(args,nc,'time','xluft',width=20,height=10,kind='',freq='',varlimits=varlimits)
        ax.set_title('Weekly medians')
        if not varlimits or (varlimits and 'xluft' not in varlimits):
            ax.set_ylim(0.975,1.025)
        df_AM_high_sza['y'].plot(ax=ax,marker='o',markersize=1,linewidth=0,color='royalblue',label='70<=SZA<=80 AM')
        df_AM_mid_sza['y'].plot(ax=ax,marker='o',markersize=1,linewidth=0,color='red',label='40<=SZA<=50 AM')
        if df_AM_low_sza['y'].size!=0:
            df_AM_low_sza['y'].plot(ax=ax,marker='o',markersize=1,linewidth=0,color='green',label='20<=SZA<=30 AM')
        if not args.flag0:
            add_qc_lines(args,nc,ax,'time','xluft')
        ax.grid()
        ax.legend(fontsize=_default_leg_font_size)
        fig_path = os.path.join(code_dir.parent,'outputs','xluft_sza_AM_vs_time.png')
        tight_layout()
        fig.savefig(fig_path,dpi=300)
        close('all')
        fig_path_list += [fig_path]

    return fig_path_list


def descend_strings(obj):
    '''
    generator function to get all the strings in an iterable object
    '''
    if hasattr(obj,'__iter__') and type(obj)!=str:
        if type(obj)==dict:
            for key in obj:
                for result in descend_strings(obj[key]):
                    yield result
        else:
            for item in obj:
                for result in descend_strings(item):
                    yield result
    elif type(obj)==str:
        yield obj


def merge_nc_files(ncin_list,var_list):
    """
    Inputs:
        - nc_in_list: list of context managers for open .nc files
        - var_list: the list of all the variables needed
    Ouputs:
        - data: dictionary with concatenated data
    """

    data = pd.DataFrame(columns=var_list)

    # if the two files overlap in time, the most recent file data will be used for the overlap period
    pop_list = [] # if a variable is missing from any of the files, don't use it at all
    print('Merging {} files'.format(len(ncin_list)))
    for i,nc in enumerate(ncin_list):
        print('\t{}'.format(os.path.basename(nc.filepath())))
        df = pd.DataFrame(columns=var_list)
        if i<len(ncin_list)-1:
            ids = np.where(nc['time'][:]<ncin_list[i+1]['time'][0])[0] # indices to slice for times in current file that come before the first time in the next file
        else:
            ids = np.arange(nc['time'].size) # for the last file, just get the whole thing
        for var in var_list:
            if var in pop_list:
                continue
            elif var not in [v for v in nc.variables]:
                if not np.any([i in var for i in ['mean','std','median']]):
                    print('Variable "{}"" is not in {}; it will be ignored in other files'.format(var,os.path.basename(nc.filepath())))
                pop_list += [var]
                continue
            df[var] = nc[var][ids]
            if var!='flagged_var_name' and np.array(nc[var][ids].mask).any():
                df[var].mask(nc[var][ids].mask,inplace=True)

        data = data.append(df,ignore_index=True)

    pop_list = list(set(pop_list))
    data.drop(columns=pop_list,inplace=True)
    setattr(data,'variables',np.array([i for i in var_list if i not in pop_list]))
    setattr(data,'long_name',nc.long_name)

    # set attributes
    for var in [i for i in var_list if i not in pop_list]:
        for key,val in nc[var].__dict__.items():
            setattr(data[var],key,val)

    return data


def nc_fname(nc):
    """
    Inputs:
        - nc: context manager of open netcdf file
    Outputs:
        - the file name
    """

    return os.path.basename(nc.filepath())


def check_mask(x):
    """
    Inputs:
        - x: dataframe column or netcdf variable
    Outputs:
        - return True is all data is NaN / masked and False otherwise
    """

    if hasattr(x[:],'data'): # masked array
        check = np.count_nonzero(x[:].mask)==x.size
    else:
        check = np.count_nonzero(np.isnan(x[:]))==x.size

    return check


def get_support_file_data(filepath, stack, args, main_time=None):
    if filepath:
        ref = stack.enter_context(netCDF4.Dataset(filepath,'r')) # input reference netcdf file
        ref_time = np.array([datetime(*cftime.timetuple()[:6]) for cftime in netCDF4.num2date(ref['time'][:],units=ref['time'].units,calendar=ref['time'].calendar)])
        all_ref_ids = np.arange(ref['time'].size)
        if args.flag0 and 'flag' in ref.variables:
            ref_flag0 = all_ref_ids[ref['flag'][:]==0]
            ref_time = ref_time[ref_flag0]
        else:
            ref_flag0 = all_ref_ids

        if main_time is not None:
            ref_outside = (ref_time < np.min(main_time)) | (ref_time > np.max(main_time))
            ref_time = ref_time[ref_outside]
            ref_flag0 = ref_flag0[ref_outside]  # we'll let the flag0 indices also subset for times not overlapping with the main data
    else:
        ref = None
        ref_time = None
        ref_flag0 = None
        ref_outside = None

    if main_time is None:
        return ref, ref_time, ref_flag0
    else:
        return ref, ref_time, ref_flag0, ref_outside


def main():
    if 'tccon-qc' not in sys.executable:
        print('Running qc_plots.py with',sys.executable)
        print('The code should be run with the tccon-qc conda environment')
    code_dir = Path(os.path.dirname(__file__)).absolute()

    parser = argparse.ArgumentParser()
    parser.add_argument('nc_in',help='full path to the netCDF file from which plots should be made, or a path to a directory (plots will be made from all *.nc files in that directory)')
    parser.add_argument('-r','--ref',default='',help='full path to another netCDF file to use as reference')
    parser.add_argument('-c', '--context', default='', help='full path to another netCDF file to use as context (i.e. full record for the site being plotted)')
    parser.add_argument('-d', '--output-dir', help='Directory to output the .pdf plots to, the default is "outputs" in the code repo')
    parser.add_argument('--flag0',action='store_true',help='only plot flag=0 data with axis ranges only within the vmin/vmax values of each variable')
    parser.add_argument('--cmap',default='PuBu',help='valid name of a matplotlib colormap https://matplotlib.org/3.1.0/tutorials/colors/colormaps.html')
    parser.add_argument('--json',default=os.path.join(code_dir.parent,'inputs','variables.json'),help='full path to the input json file for variables to plot')
    parser.add_argument('--json-limits',default=os.path.join(code_dir.parent,'inputs','limits.json'),help='full path to the input json file for axis ranges')
    parser.add_argument('--show-all',action='store_true',help='if given, the axis ranges of the plots will automatically fit in all the data, even huge outliers')
    parser.add_argument('--roll-window',type=int,default=500,help='Size of the rolling window in number of spectra')
    parser.add_argument('--roll-gaps',default='20000 days',help='Minimum time interval for which the data will be split for rolling stats')
    parser.add_argument('--size',choices=('small','medium','large'),default='medium',help='Size of the figures, default is %(default)s')
    parser.add_argument('--quality',choices=('low','medium','high'),default='high',help='Quality of the figures, default is %(default)s')

    email_grp = parser.add_mutually_exclusive_group()
    email_grp.add_argument('--email',nargs=2,default=[None,None],help='sender email followed by receiver email; by default uses the local email server, but can also work with Outlook accounts and Gmail accounts that enabled less secured apps access. For multiple recipients the second argument should be comma-separated email addresses')
    email_grp.add_argument('--email-config', help='A .toml file that sets how emails should be sent.')
    email_grp.add_argument('--gen-email-config', action='store_true', help='Create a default email config TOML file and exit. The usual positional argument (NC_IN) will be used as the path to create the TOML file at')
    args = parser.parse_args()

    if args.gen_email_config:
        with open(args.nc_in, 'w') as f:
            f.write(_default_email_cfg.lstrip())
        sys.exit()

    if not os.path.exists(args.nc_in):
        sys.exit('Invalid path for nc_in: {}'.format(args.nc_in))
    if args.ref and not os.path.exists(args.ref):
        sys.exit('Invalid path for --ref: {}'.format(args.ref))
    if args.context and not os.path.exists(args.context):
        sys.exit('Invalid path for --context: {}'.format(args.context))
    if not os.path.exists(args.json):
        sys.exit('Invalid path for --json: {}'.format(args.json))

    if args.cmap not in colormaps():
        sys.exit('{} is an Invalid --cmap value, must be one of {}'.format(args.cmap,colormaps()))

    with open(args.json_limits,'r') as f:
        varlimits = json.load(f)

    with open(args.json,'r') as f:
        vardata = json.load(f)

    var_list = list(set([i for i in descend_strings(vardata)]+['time','flag','flagged_var_name','azim','solzen','xluft']+list(vardata.keys())))

    fig_path_list = []
    with ExitStack() as stack:
        if os.path.isdir(args.nc_in):
            nc_file_list = [i for i in os.listdir(args.nc_in) if i.endswith('.nc')]
            if len(nc_file_list)==0:
                sys.exit('There are no .nc files in {}'.format(args.nc_in))           
            ncin_list = [stack.enter_context(netCDF4.Dataset(os.path.join(args.nc_in,nc_file),'r')) for nc_file in nc_file_list]
            ncin_list = [ncin_list[i] for i in np.argsort([ncin['time'][0] for ncin in ncin_list])] # sort the list of .nc files by starting date
            pdf_name = '{}{}'.format(nc_fname(ncin_list[0])[:10],nc_fname(ncin_list[-1])[10:]) # Use the first and last file names for the name of the output pdf  
            nc = merge_nc_files(ncin_list,var_list)
        else:
            pdf_name = os.path.basename(args.nc_in)
            nc = TcconData.create(args.nc_in, stack, force_flag0=False)

        # Get the netCDF handle, time coordinate, and flag data for the reference and context files,
        # if given
        ref = TcconData.create(args.ref, stack, force_flag0=args.flag0)
        context = TcconData.create(args.context, stack, force_flag0=False, exclude_times=nc.time)

        if not args.flag0:
            fig_path_list += [flag_analysis(code_dir,nc)]

        print('Making default plots')
        fig_path_list += default_plots(args,code_dir,nc,varlimits=varlimits)

        fnum = 0
        for xvar in vardata.keys():
            if xvar.startswith("roll"):
                fig_path_list += simple_plots(args,code_dir,nc,ref,context,vardata,xvar,varlimits=varlimits)      
                continue
            elif xvar.endswith("median"):
                fig_path_list += simple_plots(args,code_dir,nc,ref,context,vardata,xvar,kind='median',freq=xvar.split('_')[0],varlimits=varlimits)
                continue
            elif xvar.endswith("mean"):
                fig_path_list += simple_plots(args,code_dir,nc,ref,context,vardata,xvar,kind='mean',freq=xvar.split('_')[0],varlimits=varlimits)
                continue
            elif xvar.endswith("std"):
                fig_path_list += simple_plots(args,code_dir,nc,ref,context,vardata,xvar,kind='std',freq=xvar.split('_')[0],varlimits=varlimits)
                continue
            elif xvar not in [v for v in nc.dset.variables]:
                print(xvar,'is not in the netCDF file')
                continue
            print('Making plots vs',xvar)
            fig_path_list += simple_plots(args,code_dir,nc,ref,context,vardata,xvar,varlimits=varlimits)
            # end of "for yvar" loop
        # end of "for xvar" loop

        if args.output_dir is not None:
            pdf_path = os.path.join(args.output_dir, pdf_name.replace('.nc', '.pdf'))
        else:
            pdf_path = os.path.join(code_dir.parent,'outputs',pdf_name.replace('.nc','.pdf'))

        if args.flag0:
            pdf_path = os.path.join(code_dir.parent,'outputs',pdf_name.replace('.nc','flag0.pdf'))
        size_divisor = {'small': 3, 'medium': 2, 'large': 1}[args.size]
        quality = {'low': 30, 'medium': 60, 'high': 95}[args.quality]
        # concatenate all .png file into a temporary .pdf file
        temp_pdf_path = pdf_path.replace('.pdf','temp.pdf')
        im_list = [stack.enter_context(Image.open(fig_path).convert('RGB')) for fig_path in fig_path_list]
        im_list = [im.resize((im.width//size_divisor, im.height//size_divisor)) for im in im_list]
        im_list[0].save(temp_pdf_path, "PDF" ,quality=quality, save_all=True, append_images=im_list[1:])

        # add bookmarks to the temporary pdf file and save the final file
        pdf_in = stack.enter_context(open(temp_pdf_path,'rb'))
        pdf_out = stack.enter_context(open(pdf_path,'wb'))

        input = PdfFileReader(pdf_in)
        output = PdfFileWriter()
        
        for i,fig_path in enumerate(fig_path_list):
            output.addPage(input.getPage(i))
            output.addBookmark(os.path.basename(fig_path).strip('.jpg'),i)

        output.write(pdf_out)

    os.remove(temp_pdf_path) # remove the temporary pdf file

    if args.email[0]:
        print('Sending {} by email from {} to {}'.format(os.path.basename(pdf_path),args.email[0],args.email[1]))
        subject = 'TCCON QC plots: {}'.format(os.path.basename(pdf_path))
        body = _default_body
        send_email(subject,body,args.email[0],args.email[1],pdf_path)
    elif args.email_config:
        site_id = os.path.basename(args.nc_in)[:2]
        send_email_from_config(args.email_config, site_id=site_id, attachment=pdf_path, nc_file=args.nc_in)


if __name__=="__main__":
    main()
